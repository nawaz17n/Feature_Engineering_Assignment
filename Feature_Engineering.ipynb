{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-1. What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition:-\n",
    "In the context of feature engineering a parameter refers to a characteristic or attribute of a feature that is used to define or transform the feature in a way that improves the performance of a machine learning model.\n",
    "\n",
    "#### Scaling Parameters:-\n",
    "In feature scaling parameters might include the minimum and maximum values for the mean and standard deviation for standardization.\n",
    "\n",
    "#### Encoding Parameters:\n",
    "In one-hot encoding a parameter might define the number of categories to encode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-2. What is correlation?\n",
    "## What does negative correlation mean?\n",
    "\n",
    "### Definition:-\n",
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
    "### Types of Correlation:\n",
    "\n",
    "#### Positive Correlation: \n",
    "When one variable increases the other variable also tends to increase. For example, height and weight often show a positive correlation.\n",
    "#### Negative Correlation: \n",
    "When one variable increases the other variable tends to decrease. For example, the amount of time spent studying and the number of errors on a test may show a negative correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "#### Definition of Machine Learning:-\n",
    "Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead of being programmed to perform a task machine learning systems learn from data, identify patterns, and make decisions based on that data. The goal of machine learning is to enable machines to improve their performance on a task over time as they are exposed to more data.\n",
    "\n",
    "### Main Components of Machine Learning\n",
    "\n",
    "#### Data:\n",
    "##### Training Data: \n",
    "The dataset used to train the machine learning model. It consists of input-output pairs where the model learns to map inputs to the correct outputs.\n",
    "##### Test Data: \n",
    "A separate dataset used to evaluate the performance of the trained model. It helps assess how well the model generalizes to unseen data.\n",
    "##### Validation Data: \n",
    "Sometimes used during training to tune model parameters and prevent overfitting.\n",
    "\n",
    "#### Features:\n",
    "Features are the individual measurable properties of the data. In supervised learning features are the input variables used to make predictions. Feature engineering, the process of selecting, modifying, creating features, is crucial for improving model performance.\n",
    "\n",
    "#### Model:\n",
    "A model is a mathematical representation of the relationship between input features and the output. Different algorithms like linear regression can be used to create models. The choice of model depends on the nature of the data and the specific task.\n",
    "\n",
    "#### Training:\n",
    "The process of feeding the training data into the model and adjusting the model parameters to minimize the error in predictions. This often involves optimization techniques such as gradient descent.\n",
    "\n",
    "#### Evaluation:\n",
    "After training the model is evaluated using test data to access its performance. Common evaluation metrics include accuracy, precision and mean squared error, depending on the type of task like classification, regression, etc.\n",
    "\n",
    "#### Deployment:\n",
    "Once a model is trained and evaluated it can be deployed in a production environment to make predictions on new unseen data. This may involve integrating the model into applications or systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-4.How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "Loss Value is a critical metric in machine learning that quantifies how well a model's predictions align with the actual outcomes. \n",
    "\n",
    "### Types of Loss Functions:\n",
    "Different loss functions are used depending on the type of problem like regression or classification.\n",
    "\n",
    "#### Mean Squared Error (MSE): \n",
    "Used in regression tasks it squares the differences between predicted and actual values penalizing larger errors more heavily.\n",
    "#### Mean Absolute Error (MAE): \n",
    "Also used in regression it takes the absolute differences treating all errors equally.\n",
    "\n",
    "### Overfitting and Underfitting:\n",
    "#### Overfitting: \n",
    "A model may achieve very low loss on training data but perform poorly on unseen data indicating it has learned noise rather than the underlying pattern.\n",
    "#### Underfitting: \n",
    "A model with high loss on both training and test data may not have learned enough from the data, indicating a need for a more complex model or better features.\n",
    "\n",
    "### Evaluation of Model Quality:\n",
    "After training the loss value is evaluated on a separate test dataset to assess how well the model generalizes to new data.\n",
    "A significant difference between training loss and test loss can indicate issues such as overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-5. What are continuous and categorical variables?\n",
    "\n",
    "In statistics and data analysis, variables are classified into different types based on their nature and the type of data they represent. Two common types of variables are continuous variables and categorical variables.\n",
    "\n",
    "### Continuous Variables:-\n",
    "Continuous variables are numerical variables that can take an infinite number of values within a given range. \n",
    "\n",
    "#### Characteristics:\n",
    "#### Infinite Possibilities: \n",
    "Continuous variables can take any value within a specified range. For example, height, weight, temperature, and time are continuous variables because they can be measured with great precision.\n",
    "#### Interval and Ratio: \n",
    "Continuous variables can be further classified into interval variables and ratio variables.\n",
    "\n",
    "\n",
    "#### Categorical Variables:-\n",
    "Categorical variables are variables that represent distinct categories or groups. They can take on a limited fixed number of possible values which are often labels or names.\n",
    "\n",
    "#### Characteristics:\n",
    "#### Discrete Categories: \n",
    "Categorical variables can only take on specific values which represent different categories. They cannot be measured on a numerical scale.\n",
    "#### Nominal and Ordinal: \n",
    "Categorical variables can be further classified into nominal variables and ordinal variables ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "\n",
    "Handling categorical variables is an essential step in preparing data for machine learning models, as many algorithms require numerical input.\n",
    "\n",
    "### 1. Label Encoding\n",
    "This technique assigns a unique integer to each category in the variable. For example, if a categorical variable has three categories: \"Red,\" \"Green,\" and \"Blue,\" they might be encoded as 0, 1, and 2, respectively.\n",
    "#### Use Case: \n",
    "Label encoding is suitable for ordinal categorical variables where the categories have a meaningful order like \"Low,\" \"Medium,\" \"High\".\n",
    "#### Limitations: \n",
    "For nominal variables label encoding can introduce unintended ordinal relationships which may misslead the model.\n",
    "### 2. One-Hot Encoding\n",
    "This technique creates binary columns for each category in the variable. For example the categories \"Red,\" \"Green,\" and \"Blue\" would be transformed into three binary columns:\n",
    "Red: [1, 0, 0]\n",
    "Green: [0, 1, 0]\n",
    "Blue: [0, 0, 1]\n",
    "#### Use Case: \n",
    "One-hot encoding is suitable for nominal categorical variables where there is no inherent order.\n",
    "#### Limitations: \n",
    "This method can lead to a high-dimensional feature space, especially if the categorical variable has many unique categories.\n",
    "### 3. Binary Encoding\n",
    "This technique combines aspects of label encoding and one-hot encoding. Each category is first converted to an integer like label encoding and then that integer is converted to binary code. \n",
    "#### Use Case: \n",
    "Binary encoding is useful when dealing with high cardinality categorical variables as it reduces the dimensionality compared to one-hot encoding.\n",
    "#### Limitations: \n",
    "It may still introduce some ordinal relationships and the interpretation of the binary columns can be less intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-7.What do you mean by training and testing a dataset?\n",
    "In machine learning, the terms training dataset and testing dataset refer to two distinct subsets of data used during the model development process. They serve different purposes and are crucial for building and evaluating machine learning models effectively.\n",
    "\n",
    "### Training Dataset\n",
    "The training dataset is the portion of the data used to train the machine learning model. It consists of input-output pairs, where the model learns to map inputs features to the correct outputs labels or target values.\n",
    "\n",
    "### Testing Dataset\n",
    "The testing dataset is a separate portion of the data that is not used during the training phase. It is used to evaluate the performance of the trained model.\n",
    "\n",
    "#### Model Evaluation: \n",
    "The primary goal of the testing dataset is to access how well the model generalizes to unseen data. It provides an unbiased evaluation of the model's performance.\n",
    "#### Performance Metrics: \n",
    "By comparing the model's predictions on the testing dataset with the actual outcomes, various performance metrics can be calculated to determine the model's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-8. What is sklearn.preprocessing?\n",
    "\n",
    "sklearn.preprocessing is a module within the Scikit-learn library, which is a popular machine learning library in Python. This module provides various functions and classes for preprocessing data before it is fed into machine learning algorithms. \n",
    "\n",
    "### StandardScaler:\n",
    "#### Purpose: \n",
    "Standardizes features by removing the mean and scaling to unit variance. This is useful when features have different units or scales.\n",
    "#### Usage: \n",
    "StandardScaler().fit_transform(X) where X is the input data.\n",
    "\n",
    "### MinMaxScaler:\n",
    "#### Purpose: \n",
    "Scales features to a specified range, usually [0, 1]. This is useful for algorithms that require bounded input.\n",
    "#### Usage: \n",
    "MinMaxScaler().fit_transform(X).\n",
    "\n",
    "### OneHotEncoder:\n",
    "#### Purpose: \n",
    "Converts categorical variables into a format that can be provided to machine learning algorithms to do a better job in prediction. It creates binary columns for each category.\n",
    "#### Usage: \n",
    "OneHotEncoder().fit_transform(X).\n",
    "\n",
    "### LabelEncoder:\n",
    "#### Purpose: \n",
    "Converts categorical labels into integers. This is useful for ordinal categorical variables.\n",
    "#### Usage: \n",
    "LabelEncoder().fit_transform(y) where y is the target variable.\n",
    "\n",
    "### OrdinalEncoder:\n",
    "#### Purpose: \n",
    "Encodes categorical features as ordinal integers. It is similar to LabelEncoder but is used for multiple columns.\n",
    "#### Usage: \n",
    "OrdinalEncoder().fit_transform(X).\n",
    "\n",
    "### PolynomialFeatures:\n",
    "#### Purpose: \n",
    "Generates polynomial and interaction features. This is useful for creating non-linear relationships in linear models.\n",
    "#### Usage: \n",
    "PolynomialFeatures(degree=2).fit_transform(X).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-9. What is a Test set?\n",
    "\n",
    "A test set is a subset of data used to evaluate the performance of a machine learning model after it has been trained. It is a crucial component of the machine learning workflow, as it provides an unbiased assessment of how well the model generalizes to new, unseen data.\n",
    "\n",
    "### Separation from Training Data:\n",
    "The test set is distinct from the training set which is used to train the model. This separation is essential to ensure that the evaluation of the model's performance is not influenced by the data it has already seen.\n",
    "\n",
    "### Unseen Data:\n",
    "The test set consists of data that the model has not encountered during the training process. This allows for a fair evaluation of the model's ability to make predictions on new data.\n",
    "\n",
    "### Performance Evaluation:\n",
    "The primary purpose of the test set is to assess the model's performance using various metrics such as accuracy, precision, mean squared error, etc. These metrics help determine how well the model is likely to perform in real-world scenarios.\n",
    "\n",
    "### Size:\n",
    "The size of the test set can vary depending on the overall dataset and the specific use case. A common practice is to allocate around 20-30% of the total dataset for testing, although this can vary based on the amount of available data and the complexity of the problem.\n",
    "\n",
    "### Model Selection and Hyperparameter Tuning:\n",
    "While the test set is used for final evaluation it is important to note that it should not be used during the model selection or hyperparameter tuning process. Instead a separate validation set is often used for these purposes to avoid overfitting to the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-10. How do we split data for model fitting (training and testing) in Python?\n",
    "## How do you approach a Machine Learning problem?\n",
    "\n",
    "### Splitting Data for Model Fitting in Python\n",
    "Particularly when using the Scikit-learn library we can easily split our dataset into training and testing sets using the train_test_split function from the sklearn.model_selection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age','sex','bmi','bp','s1','s2','s3','s4','s5','s6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (89, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353,), (89,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach to a Machine Learning Problem\n",
    "\n",
    "#### Define the Problem:\n",
    "Clearly define the problem you are trying to solve. Is it a classification, regression, clustering, or another type of problem Understanding the objective is crucial.\n",
    "\n",
    "#### Collect Data:\n",
    "Gather the necessary data for your problem. This could involve collecting data from various sources, such as databases, APIs, or web scraping.\n",
    "\n",
    "#### Explore and Understand the Data:\n",
    "Perform exploratory data analysis (EDA) to understand the data's structure, distribution, and relationships. Use visualizations and summary statistics to gain insights.\n",
    "\n",
    "#### Preprocess the Data:\n",
    "Clean the data by handling missing values, removing duplicates, and correcting inconsistencies.\n",
    "Transform the data as needed, which may include encoding categorical variables, scaling numerical features, and normalizing data.\n",
    "\n",
    "#### Split the Data:\n",
    "Divide the dataset into training and testing sets using techniques like train_test_split.\n",
    "\n",
    "#### Select a Model:\n",
    "Choose an appropriate machine learning algorithm based on the problem type and the nature of the data. Common algorithms include linear regression, decision trees, support vector machines etc.\n",
    "\n",
    "#### Train the Model:\n",
    "Fit the model to the training data. This involves using the training set to allow the model to learn the underlying patterns.\n",
    "\n",
    "#### Evaluate the Model:\n",
    "Use the test set to evaluate the model's performance. Calculate relevant metrics to access how well the model generalizes to unseen data.\n",
    "\n",
    "#### Make Predictions:\n",
    "Once satisfied with the model's performance, use it to make predictions on new data.\n",
    "\n",
    "#### Deploy the Model:\n",
    "If the model performs well, deploy it in a production environment where it can be used to make predictions on real-world data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-11. Why do we have to perform EDA before fitting a model to the data?\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a critical step in the data science and machine learning workflow. It involves analyzing and visualizing the data to understand its structure, patterns, and relationships before fitting a model. Here are several reasons why performing EDA is essential:\n",
    "\n",
    "### 1. Understanding the Data\n",
    "EDA helps you understand the types of data you have  numerical, categorical and their distributions. This understanding is crucial for selecting appropriate preprocessing techniques and models.\n",
    "\n",
    "### 2. Identifying Data Quality Issues\n",
    "#### Missing Values: \n",
    "EDA allows you to detect missing values in the dataset. Understanding the extent and pattern of missing data is essential for deciding how to handle it .\n",
    "#### Outliers: \n",
    "Identifying outliers can help you understand whether they are errors, anomalies, or valid extreme values. Outliers can significantly affect model performance, so knowing their presence is crucial.\n",
    "#### Inconsistencies: \n",
    "EDA can reveal inconsistencies in the data, such as duplicate records or incorrect data types, which need to be addressed before modeling.\n",
    "### 3. Feature Engineering Opportunities\n",
    "#### Creating New Features: \n",
    "EDA can help identify opportunities for feature engineering, such as creating interaction terms, aggregating features, or transforming variables .\n",
    "#### Encoding Categorical Variables: \n",
    "Understanding the distribution of categorical variables can guide you in choosing the right encoding techniques like one-hot encoding, label encoding.\n",
    "### 4. Choosing the Right Model\n",
    "#### Model Selection: \n",
    "Different models have different assumptions about the data. EDA helps you understand the underlying patterns and distributions, which can inform your choice of model .\n",
    "#### Understanding Relationships: \n",
    "Visualizations can help you identify linear or non-linear relationships, which can guide the selection of appropriate algorithms.\n",
    "### 5. Hypothesis Generation\n",
    "#### Formulating Hypotheses: \n",
    "EDA can help generate hypotheses about the data, which can be tested during modeling. For example, you might hypothesize that certain features are correlated with the target variable based on visualizations.\n",
    "### 6. Improving Model Performance\n",
    "#### Data Transformation: \n",
    "Insights gained from EDA can lead to better data transformations, which can improve model performance. For example, normalizing or scaling features based on their distributions can enhance the training process.\n",
    "#### Feature Selection: \n",
    "EDA can help identify irrelevant or redundant features, allowing you to focus on the most important variables, which can lead to simpler and more interpretable models.\n",
    "### 7. Communicating Insights\n",
    "#### Visualization: \n",
    "EDA provides visualizations that can help communicate findings to stakeholders. Clear visual representations of data can facilitate discussions about the data and the modeling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-12. What is correlation?\n",
    "\n",
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. It quantifies how changes in one variable are associated with changes in another variable. Correlation is commonly used in statistics and data analysis to identify and understand relationships between different datasets.\n",
    "### Types of Correlation:\n",
    "\n",
    "#### Positive Correlation: \n",
    "When one variable increases the other variable also tends to increase. For example, height and weight often show a positive correlation.\n",
    "#### Negative Correlation: \n",
    "When one variable increases the other variable tends to decrease. For example, the amount of time spent studying and the number of errors on a test may show a negative correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-13. What does negative correlation mean?\n",
    "\n",
    "Negative correlation refers to a statistical relationship between two variables in which one variable increases while the other variable decreases. In other words, when one variable moves in one direction the other variable tends to move in the opposite direction. This type of correlation indicates an inverse relationship between the two variables.\n",
    "\n",
    "\n",
    "### Correlation Coefficient:\n",
    "The strength and direction of a negative correlation are quantified using a correlation coefficient, which ranges from -1 to 0 for negative correlations.\n",
    "A correlation coefficient close to -1 indicates a strong negative correlation, meaning that as one variable increases, the other decreases in a consistent manner.\n",
    "A correlation coefficient close to 0 indicates a weak negative correlation, meaning that there is little to no linear relationship between the two variables.\n",
    "\n",
    "### Graphical Representation:\n",
    "Negative correlation can be visualized using a scatter plot. In such a plot, points will tend to slope downwards from left to right, indicating that as the value of one variable increases, the value of the other variable decreases.\n",
    "\n",
    "### Examples of Negative Correlation:\n",
    "#### Temperature and Heating Costs: \n",
    "As the temperature increases, the heating costs typically decrease, indicating a negative correlation.\n",
    "#### Exercise and Body Weight: \n",
    "Generally, as the amount of exercise increases, body weight tends to decrease, suggesting a negative correlation.\n",
    "\n",
    "### Interpretation of Negative Correlation\n",
    "#### Inverse Relationship: \n",
    "A negative correlation suggests that the two variables are inversely related. Understanding this relationship can be useful in various fields, such as economics, psychology, and health sciences.\n",
    "#### Predictive Insights: \n",
    "In predictive modeling, recognizing a negative correlation can help in understanding how changes in one variable may affect another, which can be valuable for decision-making and strategy development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-14. How can you find correlation between variables in Python?\n",
    "\n",
    "We can find the correlation between variables using Pandas and NumPy.\n",
    "\n",
    "### Using Pandas\n",
    "Pandas provides a convenient way to calculate correlation using the corr() method on DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1],\n",
    "    'C': [2, 3, 4, 5, 6]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "A  1.0 -1.0  1.0\n",
       "B -1.0  1.0 -1.0\n",
       "C  1.0 -1.0  1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NumPy\n",
    "You can also use NumPy to calculate the correlation coefficient between two variables using the numpy.corrcoef() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 2, 3, 4, 5])\n",
    "B = np.array([5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.],\n",
       "       [-1.,  1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_coefficient = np.corrcoef(A, B)\n",
    "correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Seaborn for Visualization\n",
    "We can also visualize the correlation matrix using the Seaborn library, which provides a heatmap for better interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1],\n",
    "    'C': [2, 3, 4, 5, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K L SATAPATHY\\AppData\\Local\\Temp\\ipykernel_24580\\497603529.py:5: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-15.What is causation? Explain difference between correlation and causation with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causation refers to a relationship between two variables where one variable directly influences or causes a change in another variable\n",
    "\n",
    "### Key Characteristics of Causation\n",
    "#### Directionality:- \n",
    "Causation implies a directional influence, meaning that one variable  leads to a change in another variable .\n",
    "#### Temporal Precedence:- \n",
    "For causation to be established the cause must occur before the effect in time.\n",
    "#### Control of Confounding Variables:- \n",
    "To establish causation it is essential to control for other variables that might influence the relationship between the two variables being studied.\n",
    "\n",
    "### Difference Between Correlation and Causation\n",
    "\n",
    "#### Definition:-\n",
    "##### Correlation:- \n",
    "A statistical measure that describes the strength and direction of a relationship between two variables. Correlation does not imply that one variable causes the other to change.\n",
    "##### Causation:- \n",
    "Indicates that one variable directly affects another. It implies a cause-and-effect relationship.\n",
    "\n",
    "### Examples:-\n",
    "\n",
    "#### Correlation Example:-\n",
    "There may be a correlation between ice cream sales and the number of people swimming at the beach. As ice cream sales increase, the number of people swimming also increases.\n",
    "#### Causation Example:-\n",
    "Smoking is known to cause lung cancer. In this case, there is a direct cause-and-effect relationship: the act of smoking leads to changes in lung tissue that can result in cancer .\n",
    "\n",
    "### Example to Illustrate the Difference:-\n",
    "\n",
    "#### Correlation Example\n",
    "##### Observation: \n",
    "There is a correlation between the number of hours studied and exam scores. As the number of hours studied increases, exam scores tend to increase.\n",
    "##### Interpretation: \n",
    "While there is a correlation, it does not necessarily mean that studying more hours directly causes higher exam scores. Other factors, such as the quality of study materials, the student's prior knowledge, and test-taking skills, may also play a significant role.\n",
    "\n",
    "#### Causation Example\n",
    "##### Observation: \n",
    "A study finds that increasing physical activity leads to weight loss.\n",
    "##### Interpretation: \n",
    "In this case we can establish causation because increasing physical activity leads to changes in energy expenditure and metabolism, resulting in weight loss ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "\n",
    "An optimizer is an algorithm or method used in machine learning and deep learning to adjust the parameters of a model in order to minimize the loss function. The loss function quantifies how well the model's predictions match the actual data. By optimizing the parameters, the optimizer helps improve the model's performance on the given task.\n",
    "\n",
    "### Types of Optimizers\n",
    "There are several types of optimizers, each with its own approach to updating model parameters.\n",
    "\n",
    "* Stochastic Gradient Descent (SGD)\n",
    "* Momentum\n",
    "* Nesterov Accelerated Gradient (NAG)\n",
    "* Adagrad\n",
    "* RMSprop\n",
    "* Adam\n",
    "* AdamW\n",
    "* FTRL (Follow The Regularized Leader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Stochastic Gradient Descent (SGD)\n",
    "SGD updates the model parameters using the gradient of the loss function with respect to the parameters. It does this for each training example, which can lead to faster convergence but also introduces noise in the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Momentum\n",
    "Momentum builds on SGD by adding a fraction of the previous update to the current update. This helps accelerate gradients in the right direction and dampens oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Nesterov Accelerated Gradient (NAG)\n",
    "NAG is a variant of momentum that looks ahead to where the parameters will be after the momentum update. This can lead to more accurate updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Adagrad\n",
    "Adagrad adapts the learning rate for each parameter based on the historical gradients. Parameters with larger gradients get smaller learning rates, while those with smaller gradients get larger learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "\n",
    "optimizer = Adagrad(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. RMSprop\n",
    "RMSprop modifies Adagrad to reduce the learning rate over time. It uses a moving average of squared gradients to normalize the gradients, which helps in dealing with non-stationary objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Adam (Adaptive Moment Estimation)\n",
    "Adam combines the advantages of both RMSprop and momentum. It maintains a moving average of both the gradients and the squared gradients, allowing for adaptive learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. AdamW\n",
    "Description: AdamW is a variant of Adam that decouples weight decay from the optimization steps. This allows for better regularization and can lead to improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. FTRL (Follow The Regularized Leader)\n",
    "Description: FTRL is an online learning algorithm that is particularly useful for large-scale problems. It combines ideas from both SGD and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.training import ftrl\n",
    "\n",
    "optimizer = ftrl.FtrlOptimizer(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-17. What is sklearn.linear_model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model is a module within the scikit-learn library, which is a popular machine learning library in Python. This module provides a variety of linear models for regression and classification tasks. Linear models are based on the assumption that the relationship between the input features and the target variable can be expressed as a linear combination of the input features.\n",
    "\n",
    "### Key Features of sklearn.linear_model\n",
    "#### Linear Regression: \n",
    "Models that predict a continuous target variable based on one or more input features.\n",
    "#### Logistic Regression: \n",
    "Used for binary classification tasks, predicting the probability that a given input belongs to a particular class.\n",
    "#### Regularization: \n",
    "Many models in this module support regularization techniques (like L1 and L2 regularization) to prevent overfitting.\n",
    "#### Support for Multi-class Classification: \n",
    "Some models can handle multi-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-18. What does model.fit() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.fit() method in scikit-learn is used to train a machine learning model on a given dataset .This method adjust the model's parameters based on the training data, allowing it to learn the underlying patterns in the data. The fit() method is a crucial step in the machine learning workflow, as it prepares the model for making predictions.\n",
    "\n",
    "### Required Arguments for model.fit()\n",
    "\n",
    "#### X:\n",
    "This is the input feature matrix. It contains the training data, where each row represents a sample and each column represents a feature.\n",
    "\n",
    "#### y:\n",
    "This is the target variable (or labels) corresponding to the input features. It contains the output values that the model is trying to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-19. What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.predict() method in scikit-learn is used to make predictions based on the trained model. After a model has been fitted to the training data using the fit() method we can use predict() to generate output for new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Arguments for model.predict()\n",
    "\n",
    "#### X:\n",
    "This is the input feature matrix for which you want to make predictions. It should contain the same number of features as the training data used in the fit() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-20. What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics and data analysis, variables are classified into different types based on their nature and the type of data they represent. Two common types of variables are continuous variables and categorical variables.\n",
    "\n",
    "### Continuous Variables:-\n",
    "Continuous variables are numerical variables that can take an infinite number of values within a given range. \n",
    "\n",
    "#### Characteristics:\n",
    "#### Infinite Possibilities: \n",
    "Continuous variables can take any value within a specified range. For example, height, weight, temperature, and time are continuous variables because they can be measured with great precision.\n",
    "#### Interval and Ratio: \n",
    "Continuous variables can be further classified into interval variables and ratio variables.\n",
    "\n",
    "\n",
    "#### Categorical Variables:-\n",
    "Categorical variables are variables that represent distinct categories or groups. They can take on a limited fixed number of possible values which are often labels or names.\n",
    "\n",
    "#### Characteristics:\n",
    "#### Discrete Categories: \n",
    "Categorical variables can only take on specific values which represent different categories. They cannot be measured on a numerical scale.\n",
    "#### Nominal and Ordinal: \n",
    "Categorical variables can be further classified into nominal variables and ordinal variables ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-21. What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is a technique used in machine learning to standardize the range of independent variables or features of the data. In many machine learning algorithms, the scale of the features can significantly impact the performance of the model. Feature scaling ensures that each feature contributes equally to the distance calculations and optimization processes, which can lead to better model performance and faster convergence during training.\n",
    "\n",
    "### Why Feature Scaling is Important\n",
    "#### Distance-Based Algorithms: \n",
    "Algorithms like k-Nearest Neighbors (k-NN) and Support Vector Machines (SVM) rely on distance calculations. If one feature has a much larger range than others, it can dominate the distance metric, leading to biased results.\n",
    "\n",
    "#### Gradient Descent Optimization: \n",
    "In algorithms that use gradient descent like linear regression features with larger ranges can cause the optimization process to converge slowly or get stuck in local minima. Scaling helps to ensure that the gradients are more uniform across features.\n",
    "\n",
    "#### Regularization: \n",
    "In models that include regularization like Lasso and Ridge regression, feature scaling ensures that the regularization term penalizes all features equally, regardless of their original scale.\n",
    "\n",
    "#### Improved Model Performance: \n",
    "Properly scaled features can lead to improved accuracy and performance of the model, as the model can learn more effectively from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling (Normalization):\n",
    "This technique scales the features to a fixed range, usually [0, 1].\n",
    "Formula: $$  X' = \\frac{X - X_{min}}{X_{max} - X_{min}}  $$\n",
    "Use Case: Useful when the distribution of the data is not Gaussian and when you want to preserve the relationships between the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization (Z-score Normalization):\n",
    "\n",
    "This technique scales the features to have a mean of 0 and a standard deviation of 1.\n",
    "Formula: $$  X' = \\frac{X - \\mu}{\\sigma}  $$\n",
    "Use Case: Useful when the data follows a Gaussian distribution. It is less sensitive to outliers compared to Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaling:\n",
    "\n",
    "This technique scales the features using statistics that are robust to outliers, such as the median and the interquartile range (IQR).\n",
    "Formula: $$ X' = \\frac{X - \\text{median}}{\\text{IQR}} $$\n",
    "Use Case: Useful when the dataset contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-22. How do we perform scaling in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling can be easily performed using the scikit-learn library, which provides several preprocessing classes specifically designed for this purpose. \n",
    "\n",
    "### 1. Min-Max Scaling (Normalization)\n",
    "Min-Max scaling transforms features to a fixed range, usually [0, 1]. This is done using the MinMaxScaler class from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [5 6]]\n",
      "Scaled Data (Min-Max):\n",
      " [[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.75 0.75]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [4, 5], [5, 6]])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Original Data:\\n\", X)\n",
    "print(\"Scaled Data (Min-Max):\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardization (Z-score Normalization)\n",
    "Standardization scales features to have a mean of 0 and a standard deviation of 1. This can be done using the StandardScaler class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [5 6]]\n",
      "Scaled Data (Standardization):\n",
      " [[-1.26491106 -1.26491106]\n",
      " [-0.63245553 -0.63245553]\n",
      " [ 0.63245553  0.63245553]\n",
      " [ 1.26491106  1.26491106]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [4, 5], [5, 6]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Original Data:\\n\", X)\n",
    "print(\"Scaled Data (Standardization):\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Robust Scaling\n",
    "Robust scaling uses the median and the interquartile range (IQR) to scale features, making it robust to outliers. This can be done using the RobustScaler class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[  1   2]\n",
      " [  2   3]\n",
      " [  4   5]\n",
      " [100   6]]\n",
      "Scaled Data (Robust Scaling):\n",
      " [[-0.07619048 -0.8       ]\n",
      " [-0.03809524 -0.4       ]\n",
      " [ 0.03809524  0.4       ]\n",
      " [ 3.6952381   0.8       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [4, 5], [100, 6]])\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Original Data:\\n\", X)\n",
    "print(\"Scaled Data (Robust Scaling):\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Pipelines for Scaling\n",
    "In practice, especially when building machine learning models, it's common to use pipelines to streamline the process of scaling and modeling. This ensures that the same scaling is applied to both training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [4, 5], [5, 6], [100, 7]])\n",
    "y = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Test Data:\n",
      " [3.30769231]\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Predictions on Test Data:\\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-23. What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.preprocessing is a module within the Scikit-learn library, which is a popular machine learning library in Python. This module provides various functions and classes for preprocessing data before it is fed into machine learning algorithms. \n",
    "\n",
    "### StandardScaler:\n",
    "#### Purpose: \n",
    "Standardizes features by removing the mean and scaling to unit variance. This is useful when features have different units or scales.\n",
    "#### Usage: \n",
    "StandardScaler().fit_transform(X) where X is the input data.\n",
    "\n",
    "### MinMaxScaler:\n",
    "#### Purpose: \n",
    "Scales features to a specified range, usually [0, 1]. This is useful for algorithms that require bounded input.\n",
    "#### Usage: \n",
    "MinMaxScaler().fit_transform(X).\n",
    "\n",
    "### OneHotEncoder:\n",
    "#### Purpose: \n",
    "Converts categorical variables into a format that can be provided to machine learning algorithms to do a better job in prediction. It creates binary columns for each category.\n",
    "#### Usage: \n",
    "OneHotEncoder().fit_transform(X).\n",
    "\n",
    "### LabelEncoder:\n",
    "#### Purpose: \n",
    "Converts categorical labels into integers. This is useful for ordinal categorical variables.\n",
    "#### Usage: \n",
    "LabelEncoder().fit_transform(y) where y is the target variable.\n",
    "\n",
    "### OrdinalEncoder:\n",
    "#### Purpose: \n",
    "Encodes categorical features as ordinal integers. It is similar to LabelEncoder but is used for multiple columns.\n",
    "#### Usage: \n",
    "OrdinalEncoder().fit_transform(X).\n",
    "\n",
    "### PolynomialFeatures:\n",
    "#### Purpose: \n",
    "Generates polynomial and interaction features. This is useful for creating non-linear relationships in linear models.\n",
    "#### Usage: \n",
    "PolynomialFeatures(degree=2).fit_transform(X).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-24. How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "particularly when using the scikit-learn library, you can easily split your dataset into training and testing sets using the train_test_split function from the sklearn.model_selection module. This function allows you to randomly partition your data into two subsets: one for training the model and the other for testing its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'feature2': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'target': [0, 0, 1, 1, 1, 0, 0, 1]\n",
    "})\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "    feature1  feature2\n",
      "1         2         3\n",
      "6         7         8\n",
      "0         1         2\n",
      "4         5         6\n",
      "3         4         5\n",
      "5         6         7\n",
      "Testing Features:\n",
      "    feature1  feature2\n",
      "7         8         9\n",
      "2         3         4\n",
      "Training Target:\n",
      " 1    0\n",
      "6    0\n",
      "0    0\n",
      "4    1\n",
      "3    1\n",
      "5    0\n",
      "Name: target, dtype: int64\n",
      "Testing Target:\n",
      " 7    1\n",
      "2    1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Features:\\n\", X_train)\n",
    "print(\"Testing Features:\\n\", X_test)\n",
    "print(\"Training Target:\\n\", y_train)\n",
    "print(\"Testing Target:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-25. Explain data encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data encoding is a crucial preprocessing step in machine learning and data analysis, particularly when dealing with categorical variables. Since most machine learning algorithms require numerical input, encoding transforms categorical data into a numerical format that can be used for modeling. \n",
    "\n",
    "### Types of Categorical Variables\n",
    "#### Nominal Variables: \n",
    "These are categorical variables without any inherent order. Examples include gender, color, and nationality.\n",
    "#### Ordinal Variables: \n",
    "These are categorical variables with a meaningful order or ranking. Examples include education level and satisfaction ratings.\n",
    "\n",
    "### Common Encoding Techniques\n",
    "#### Label Encoding:\n",
    "This technique assigns a unique integer to each category in a categorical variable. It is suitable for ordinal variables where the order matters.\n",
    "Example:\n",
    "* Categories: ['Low', 'Medium', 'High']\n",
    "* Encoded: {'Low': 0, 'Medium': 1, 'High': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categories = ['Low', 'Medium', 'High', 'Medium', 'Low']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "encoded_labels = label_encoder.fit_transform(categories)\n",
    "\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding:\n",
    "This technique creates binary (0 or 1) columns for each category in a categorical variable. It is suitable for nominal variables where there is no inherent order.\n",
    "Example:\n",
    "* Categories: ['Red', 'Green', 'Blue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color_Blue  Color_Green  Color_Red\n",
       "0           0            0          1\n",
       "1           0            1          0\n",
       "2           1            0          0\n",
       "3           0            1          0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Color': ['Red', 'Green', 'Blue', 'Green']})\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df, columns=['Color']).astype(int)\n",
    "\n",
    "one_hot_encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoding:\n",
    "This technique combines the properties of label encoding and one-hot encoding. It first converts categories into integers and then converts those integers into binary code. Each binary digit is then treated as a separate feature.\n",
    "Example:\n",
    "* Categories: ['Red', 'Green', 'Blue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "df = pd.DataFrame({'Color': ['Red', 'Green', 'Blue', 'Green']})\n",
    "\n",
    "binary_encoder = BinaryEncoder()\n",
    "\n",
    "binary_encoded = binary_encoder.fit_transform(df['Color'])\n",
    "\n",
    "print(binary_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding:\n",
    "\n",
    "This technique replaces each category with the mean of the target variable for that category. It is particularly useful for high-cardinality categorical variables.\n",
    "Example:\n",
    "* Categories: ['A', 'B', 'A', 'C']\n",
    "* Target: [1, 0, 1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Target_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  Target_Encoded\n",
       "0        A             1.0\n",
       "1        B             0.0\n",
       "2        C             0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Category': ['A', 'B', 'A', 'C'], 'Target': [1, 0, 1, 0]})\n",
    "\n",
    "target_encoded = df.groupby('Category')['Target'].mean().reset_index()\n",
    "target_encoded.columns = ['Category', 'Target_Encoded']\n",
    "\n",
    "target_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Label Encoding: Use for ordinal variables where the order matters.\n",
    "* One-Hot Encoding: Use for nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
